{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7aa727e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\dengz\\\\Desktop\\\\Projects\\\\cnn_classifier\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e22d75de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\dengz\\\\Desktop\\\\Projects\\\\cnn_classifier'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00556511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PredictionConfig:\n",
    "    path_of_model: Path\n",
    "    training_data: Path\n",
    "    all_params: dict\n",
    "    params_image_size: list\n",
    "    params_num_classes: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "010e446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories, save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a763ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config_filepath=CONFIG_FILE_PATH,\n",
    "                 params_filepath=PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath) \n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_predict_config(self) -> PredictionConfig:\n",
    "            predict_config = PredictionConfig(\n",
    "            path_of_model=Path(\"artifacts/training/model.pt\"),\n",
    "            training_data=Path(\"artifacts/data_ingestion/Chest-CT-Scan-data\"),\n",
    "            all_params=self.params,\n",
    "            params_image_size=self.params.IMAGE_SIZE,\n",
    "            params_num_classes=self.params.CLASSES\n",
    "        )\n",
    "            return predict_config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e6e0683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models, datasets\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from cnnClassifier.entity.config_entity import TrainingConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcdc5e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction:\n",
    "    def __init__(self,\n",
    "                 filename: str,\n",
    "                 config: TrainingConfig,\n",
    "                 device: torch.device = None):\n",
    "        \"\"\"\n",
    "        :param filename: Path to the image to predict\n",
    "        :param config: TrainingConfig instance for model construction and loading\n",
    "        :param device: torch.device, optional. Automatically selects GPU/CPU if not specified\n",
    "        \"\"\"\n",
    "        self.filename = filename\n",
    "        self.config = config\n",
    "        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # Load class names (subfolder names from ImageFolder)\n",
    "        self.class_names = datasets.ImageFolder(self.config.training_data).classes\n",
    "        print(f\"Class index mapping: {{i: name for i, name in enumerate(self.class_names)}}\")\n",
    "\n",
    "        # Build and load model\n",
    "        self.model = self._load_model()\n",
    "\n",
    "    def _load_model(self) -> nn.Module:\n",
    "        # Model architecture should match training configuration\n",
    "        model = models.resnet18(weights=None)\n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_features, self.config.params_num_classes)\n",
    "\n",
    "        # Load trained weights\n",
    "        state_dict = torch.load(self.config.path_of_model, map_location=self.device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.to(self.device).eval()\n",
    "        return model\n",
    "\n",
    "    def predict(self) -> list:\n",
    "        # Preprocessing pipeline (should match training transformations)\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize(self.config.params_image_size[:2]),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        # Load and process image\n",
    "        img = Image.open(self.filename).convert('RGB')\n",
    "        input_tensor = preprocess(img).unsqueeze(0).to(self.device)\n",
    "\n",
    "        # Inference\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_tensor)\n",
    "            probs = torch.softmax(outputs, dim=1).squeeze(0)\n",
    "            idx = int(probs.argmax())\n",
    "            confidence = float(probs[idx])\n",
    "\n",
    "        label = self.class_names[idx]\n",
    "        print(f\"Predicted result: index {idx} -> class '{label}', confidence {confidence:.3f}\")\n",
    "\n",
    "        # Return structured result\n",
    "        return [{\n",
    "            \"index\": idx,\n",
    "            \"label\": label,\n",
    "            \"confidence\": confidence\n",
    "        }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c550bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-27 21:21:35,917: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-04-27 21:21:35,920: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-04-27 21:21:35,921: INFO: common: created directory at: artifacts]\n",
      "Class index mapping: {i: name for i, name in enumerate(self.class_names)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dengz\\AppData\\Local\\Temp\\ipykernel_18504\\3969338253.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(self.config.path_of_model, map_location=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted result: index 0 -> class 'adenocarcinoma', confidence 0.998\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    file = Path(r\"C:\\Users\\dengz\\Desktop\\Projects\\cnn_classifier\\artifacts\\data_ingestion\\Chest-CT-Scan-data\\adenocarcinoma\\000000 (6).png\")\n",
    "    config = ConfigurationManager()\n",
    "    eval_config = config.get_predict_config()\n",
    "    evaluation = Prediction(file,eval_config)\n",
    "    evaluation.predict()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn_classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
